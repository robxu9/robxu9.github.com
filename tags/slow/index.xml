<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Slow on Robert Xu</title>
    <link>http://www.robxu9.com/tags/slow/</link>
    <description>Recent content in Slow on Robert Xu</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>me@robxu9.com (Robert Xu)</managingEditor>
    <webMaster>me@robxu9.com (Robert Xu)</webMaster>
    <copyright>© 2014-2015 Robert Xu. All Rights Reserved. Content not indicative of any addl party.</copyright>
    <lastBuildDate>Fri, 01 Aug 2014 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://www.robxu9.com/tags/slow/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>stdout is slow</title>
      <link>http://www.robxu9.com/2014/08/stdout-is-slow/</link>
      <pubDate>Fri, 01 Aug 2014 00:00:00 +0000</pubDate>
      <author>me@robxu9.com (Robert Xu)</author>
      <guid>http://www.robxu9.com/2014/08/stdout-is-slow/</guid>
      <description>

&lt;p&gt;Reading or writing any sort of stream can be slow.  I cannot stress how much
that is true.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s incredibly noticeable, especially when you have some sort of GUI program
in debug mode and it prints out a load of stuff. Each printout, whether it&amp;rsquo;s
piped somewhere else or goes to the console, can add time that matters to your
program&amp;rsquo;s execution.&lt;/p&gt;

&lt;h3 id=&#34;why-bring-it-up-now:8e44ed532c74307615cde872e9d5796a&#34;&gt;Why bring it up now?&lt;/h3&gt;

&lt;p&gt;Take for example, &lt;code&gt;libdpx&lt;/code&gt;. I haven&amp;rsquo;t silenced any of the debug output; rather
I use it to my advantage so that I can trace where things are going. I&amp;rsquo;ve
caught several rather significant bugs this way, since tracing with &lt;code&gt;gdb&lt;/code&gt; is
rather hard on a coroutine library.&lt;/p&gt;

&lt;p&gt;But what about performance?&lt;/p&gt;

&lt;p&gt;According to &lt;a href=&#34;http://zeromq.org/results:perf-howto&#34;&gt;ØMQ&lt;/a&gt;, their performance in
terms of latency (which is the only one I have tested with duplex) for 100000
1-byte messages is a mere 30.9 microseconds, a figure I was able to replicate
locally. Jeff mentioned that I could look into performance with &lt;code&gt;libdpx&lt;/code&gt;, and I
said &amp;ldquo;sure, why not?&amp;rdquo;&lt;/p&gt;

&lt;p&gt;The tests are practically identical to the ØMQ ones - I have a receiver and a
sender of messages. And what I got initially stunned me:
{% highlight shell-session %}
$ ./send_lat 127.0.0.1 9999 1 100000&lt;/p&gt;

&lt;h1 id=&#34;lots-of-stdout-here:8e44ed532c74307615cde872e9d5796a&#34;&gt;lots of stdout here&lt;/h1&gt;

&lt;p&gt;message size: 1 bytes
message count: 100000
avg latency: 6788597.849 nanoseconds
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s 6788.6 microseconds. Yikes!&lt;/p&gt;

&lt;h3 id=&#34;save-the-output-for-debugging-only:8e44ed532c74307615cde872e9d5796a&#34;&gt;save the output for debugging only&lt;/h3&gt;

&lt;p&gt;I went ahead today and created a &lt;code&gt;DEBUG_FUNC(...)&lt;/code&gt; macro, which &lt;code&gt;#ifdef DEBUG&lt;/code&gt;
would actually execute anything inside the function, and if not, would delete
anything there.&lt;/p&gt;

&lt;p&gt;So then I wrapped all my not-important &lt;code&gt;printf&lt;/code&gt; statements with &lt;code&gt;DEBUG_FUNC&lt;/code&gt;,
and the errors I separated out into &lt;code&gt;fprintf(stderr, ...)&lt;/code&gt;. And then what did
I find?&lt;/p&gt;

&lt;p&gt;{% highlight shell-session %}
$ ./send_lat 127.0.0.1 9999 1 100000
message size: 1 bytes
message count: 100000
avg latency: 129588.328 nanoseconds
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;129.6 microseconds. A huge improvement. And because I didn&amp;rsquo;t write to stdout at
all.&lt;/p&gt;

&lt;h3 id=&#34;writing-means-disk-i-o:8e44ed532c74307615cde872e9d5796a&#34;&gt;writing means disk i/o&lt;/h3&gt;

&lt;p&gt;But this is particularly true for anything - if you write to anything, there is
going to be overhead because of flushing the stream to disk or wherever it
wants to go.&lt;/p&gt;

&lt;p&gt;Remember that advice about writing to files in C? You have to flush the stream
before closing it, or changes aren&amp;rsquo;t written to disk. It&amp;rsquo;s the same thing with
&lt;code&gt;stdout&lt;/code&gt; - &lt;code&gt;stdout&lt;/code&gt; is a file, after all.&lt;/p&gt;

&lt;p&gt;This is because files like &lt;code&gt;stdout&lt;/code&gt; are line buffered by default - so anything
will stay in the buffer until it hits a newline, at which point the program
essentially pauses to force everything to the file.&lt;/p&gt;

&lt;p&gt;From what I know, there are three types of buffering:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;No buffering, so anything written will be flushed immediately to disk.&lt;/li&gt;
&lt;li&gt;Block buffering, so after a certain length or manual call it will flush.&lt;/li&gt;
&lt;li&gt;Line buffering, so after a &lt;code&gt;\n&lt;/code&gt; it will flush.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;A note here that was made on &lt;a href=&#34;http://stackoverflow.com/a/171662
1/438175&#34;&gt;Stack Overflow&lt;/a&gt; is that &lt;code&gt;stderr&lt;/code&gt; isn&amp;rsquo;t buffered because it&amp;rsquo;s standard error - so
naturally it wants to get the error to you as quickly as possible, even if it
means slowing down everything else.&lt;/p&gt;

&lt;p&gt;You can set any stream&amp;rsquo;s buffering characteristics with &lt;a href=&#34;http://www.cplusplus.com/reference/cstdio/setvbuf/&#34;&gt;&lt;code&gt;setvbuf()&lt;/code&gt;&lt;/a&gt; - either full buffering,
line buffering, or no buffering. Practically all files are opened with
full buffering (hence the advice to flush before you close), while files like
&lt;code&gt;stdout&lt;/code&gt; are line buffered, and &lt;code&gt;stderr&lt;/code&gt; is not even buffered at all.&lt;/p&gt;

&lt;p&gt;And that flushing takes CPU cycles. It has to empty out the buffer by writing
it to disk, an operation that is costly because it&amp;rsquo;s disk i/o, and then it
has to clear the buffer before it can resume execution.&lt;/p&gt;

&lt;p&gt;While SSDs speed up disk i/o by a noticeable margin, not everyone has SSDs. So
just please don&amp;rsquo;t &lt;code&gt;printf&lt;/code&gt; in your library. It makes an impact.&lt;/p&gt;

&lt;h3 id=&#34;how-should-i-handle-logging-then-in-a-high-performance-application:8e44ed532c74307615cde872e9d5796a&#34;&gt;how should I handle logging then in a high performance application?&lt;/h3&gt;

&lt;p&gt;This is a difficult topic. Some of my suggestions in the past have been to
write on a dedicated thread; that is, print whatever you need but only flush
on a dedicated thread, so that way that thread is the slow one while the
others can continue.&lt;/p&gt;

&lt;p&gt;But I guess I would mention that it really depends on what you&amp;rsquo;re making.
Sometimes, forwarding any output to a logging server might be better. Maybe
block buffering instead of line buffering &lt;code&gt;stdout&lt;/code&gt;. Write your own functions.
I don&amp;rsquo;t know.&lt;/p&gt;

&lt;p&gt;Some interesting ones have been making a channel across threads, and then
sending log messages that are marked with your thread name &amp;amp; time to another
thread to be finally processed and outputted, where in a worker thread:&lt;/p&gt;

&lt;p&gt;{% highlight go %}
mylog.Send(fmt.Sprintf(&amp;ldquo;my logging message&amp;rdquo;))
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;which sends it through a channel to the logging thread, which then:&lt;/p&gt;

&lt;p&gt;{% highlight go %}
for log := range logChan {
    fmt.Printf(&amp;ldquo;%s %s: %s\n&amp;rdquo;, log.Time, log.Threadname, log.Message)
}
{% endhighlight %}&lt;/p&gt;

&lt;p&gt;Or something like that. Again, I really guess it depends on what you want to
do.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>